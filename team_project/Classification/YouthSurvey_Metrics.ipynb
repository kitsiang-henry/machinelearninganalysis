{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions to perform EDA, Col transformation to prepare for training/testing\n",
    "x_cols = [\"gender\",\"freq_see_elderly\",\"knowledge_elderly_pop\",\"freq_interact_w_elderly\",\"difficulties_interacting\",\"disrupt_student_lives\",\"thoughts_inter_hub\"]\n",
    "y_col = \"interest_csp_elderly_smu\"\n",
    "\n",
    "\n",
    "def prepare_data(x_cols,y_col):\n",
    "    df = pd.read_csv(\"youth_opinions_3.csv\")\n",
    "\n",
    "    for col in df:\n",
    "        #get dtype for column\n",
    "        dt = df[col].dtype \n",
    "        #check if it is a number\n",
    "        if dt == int or dt == float:\n",
    "            df[col] = df[col].fillna(0)\n",
    "        else:\n",
    "            df[col] = df[col].fillna(\"-\")\n",
    "    \n",
    "    #renamed columns\n",
    "\n",
    "    df.columns = ['gender','faculty','ug_pg','year','csp_cleared','cleared_mode',\n",
    "                  'clearing_plan','freq_see_elderly','elderly_do','knowledge_elderly_pop','freq_interact_w_elderly',\n",
    "                  'difficulties_interacting','difficulties_face','interest_participate_elderly_center_csp','thoughts_inter_hub','thoughts','brand',\n",
    "                  'disrupt_student_lives','disrupt_reason','interest_csp_elderly_smu']\n",
    "\n",
    "    #Encode textual data into classes\n",
    "    df['csp_cleared'] = (df['csp_cleared'] == 'Yes' ).astype(int)\n",
    "    df['knowledge_elderly_pop'] = (df['knowledge_elderly_pop'] == 'Yes' ).astype(int)\n",
    "    df['difficulties_interacting'] = (df['difficulties_interacting'] == 'Yes' ).astype(int)\n",
    "    df['interest_participate_elderly_center_csp'] = (df['interest_participate_elderly_center_csp'] == 'Yes' ).astype(int)\n",
    "    df['disrupt_student_lives'] = (df['disrupt_student_lives'] == 'Yes' ).astype(int)\n",
    "\n",
    "    df[\"gender\"] = df[\"gender\"].apply(encode_gender)\n",
    "    df[\"gender\"] = df[\"gender\"].astype(int)\n",
    "    \n",
    "    df['thoughts_inter_hub'] = df['thoughts_inter_hub'].apply(encode_score)\n",
    "    df['thoughts_inter_hub'] = df['thoughts_inter_hub'].astype(int)\n",
    "    \n",
    "    elderly_related = df[\"cleared_mode\"]+ df[\"clearing_plan\"]\n",
    "    df[\"csp_elderly_related\"] = elderly_related.apply(score_csp_elderly)\n",
    "    \n",
    "    \n",
    "    df[\"year\"] = df[\"year\"].apply(remove_year_text)\n",
    "    df[\"year\"] = df[\"year\"].astype(int)\n",
    "    \n",
    "\n",
    "    series = []\n",
    "    for col in x_cols:\n",
    "        series.append(df[col])\n",
    "\n",
    "    x_df = pd.concat(series,axis=1)\n",
    "    \n",
    "    x_data = x_df\n",
    "    prepped_y = df[y_col].apply(prep_class_labels)\n",
    "    y_data = prepped_y\n",
    "    \n",
    "    return x_data,y_data\n",
    "\n",
    "    \n",
    "def prep_class_labels(data):\n",
    "    if data >= 3:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "#Encode the thoughts on intergenerational hub\n",
    "def encode_score(data):\n",
    "    if data == \"That's an excellent idea!\":\n",
    "        return 4\n",
    "    if data == \"That's good!\":\n",
    "        return 3\n",
    "    if data == \"Not bad\":\n",
    "        return 2\n",
    "    if data == \"Don't really feel good about it\":\n",
    "        return 1\n",
    "    if data == \"No way!\":\n",
    "        return 0\n",
    "    \n",
    "def encode_gender(data):\n",
    "    if data == \"Male\":\n",
    "        return 1\n",
    "    if data == \"Female\":\n",
    "        return 0\n",
    "\n",
    "def score_csp_elderly(data):\n",
    "    words_related = [\"elderly\",\"Inspirar\",\"old\",\"folks\"]\n",
    "    might_be_words_related = [\"Uni-Y\",\"uniy\",\"uni-y\",\"rotaract\",\"Rotaract\"]\n",
    "    if any(word in data for word in words_related):\n",
    "        return 2\n",
    "    elif any(word in data for word in might_be_words_related):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "def remove_year_text(data):\n",
    "    if data == \"-\":\n",
    "        return 0\n",
    "    data = data.replace(\"Year\",\"\")\n",
    "    data = int(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    0.648649\n",
      "0    0.351351\n",
      "Name: interest_csp_elderly_smu, dtype: float64\n",
      "Probability of Interested in Elderly CSP in SMU: 0.6486486486486487 %\n",
      "Probability of NOT Interested in Elderly CSP in SMU: 0.35135135135135137 %\n"
     ]
    }
   ],
   "source": [
    "x_data, y_data = prepare_data(x_cols,y_col)\n",
    "\n",
    "\n",
    "#Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_data, y_data, test_size = 0.15, \n",
    "                                                          stratify = y_data,\n",
    "                                                          random_state = 1)\n",
    "\n",
    "\n",
    "\n",
    "print(y_data.value_counts(1))\n",
    "print(\"Probability of Interested in Elderly CSP in SMU:\",y_data.value_counts(1)[1],\"%\")\n",
    "print(\"Probability of NOT Interested in Elderly CSP in SMU:\",y_data.value_counts(1)[0],\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load all the saved models\n",
    "\n",
    "path = \"./backup_best_models/\"\n",
    "\n",
    "regressor = joblib.load(path + \"logistic_regression_youth.sav\")\n",
    "nb = joblib.load(path + \"naive_bayes_youth.sav\")\n",
    "dt = joblib.load(path + \"decision_tree_youth.sav\")\n",
    "random_forest = joblib.load(path + \"random_forest_classifier_youth.sav\")\n",
    "best_tree = joblib.load(path + \"random_forest_best_tree_youth.sav\")\n",
    "clf = joblib.load(path + \"SVM_youth.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Measures\n",
      "[[8 0]\n",
      " [1 3]]\n",
      "Specificity : 0.75\n",
      "Precision : 0.89\n",
      "Recall or Sensitivity : 1.0\n",
      "F Score 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic Regression Measures\")\n",
    "y_predict = regressor.predict(X_test)\n",
    "\n",
    "#cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict, labels = [1,0])\n",
    "print(cnf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall_or_sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(\"Specificity :\", round(specificity,2))\n",
    "print(\"Precision :\", round(precision, 2))\n",
    "print(\"Recall or Sensitivity :\", round(recall_or_sensitivity, 2))\n",
    "print(\"F Score\",f1_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Measures\n",
      "[[7 1]\n",
      " [2 2]]\n",
      "Specificity : 0.5\n",
      "Precision : 0.78\n",
      "Recall or Sensitivity : 0.88\n",
      "F Score 0.823529411764706\n",
      "[0 1]\n",
      "[0.35135135 0.64864865]\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes Measures\")\n",
    "y_predict = nb.predict(X_test)\n",
    "\n",
    "#cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict, labels = [1,0])\n",
    "print(cnf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall_or_sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(\"Specificity :\", round(specificity,2))\n",
    "print(\"Precision :\", round(precision, 2))\n",
    "print(\"Recall or Sensitivity :\", round(recall_or_sensitivity, 2))\n",
    "print(\"F Score\",f1_score(y_test, y_predict))\n",
    "\n",
    "print(nb.classes_)\n",
    "print(nb.class_prior_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Measures\n",
      "[[7 1]\n",
      " [1 3]]\n",
      "Specificity : 0.75\n",
      "Precision : 0.88\n",
      "Recall or Sensitivity : 0.88\n",
      "F Score 0.875\n"
     ]
    }
   ],
   "source": [
    "print(\"Decision Tree Measures\")\n",
    "y_predict = dt.predict(X_test)\n",
    "\n",
    "#cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict, labels = [1,0])\n",
    "print(cnf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall_or_sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(\"Specificity :\", round(specificity,2))\n",
    "print(\"Precision :\", round(precision, 2))\n",
    "print(\"Recall or Sensitivity :\", round(recall_or_sensitivity, 2))\n",
    "print(\"F Score\",f1_score(y_test, y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Measures\n",
      "[[6 2]\n",
      " [0 4]]\n",
      "4 0 2 6\n",
      "Specificity : 1.0\n",
      "Precision : 1.0\n",
      "Recall or Sensitivity : 0.75\n",
      "F Score 0.8571428571428571\n",
      "0.10630759355315132 : gender\n",
      "0.20309410156126162 : freq_see_elderly\n",
      "0.07918856644678446 : knowledge_elderly_pop\n",
      "0.13782349399623556 : freq_interact_w_elderly\n",
      "0.0435029792672991 : difficulties_interacting\n",
      "0.09795554723295223 : disrupt_student_lives\n",
      "0.3321277179423158 : thoughts_inter_hub\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier Measures\")\n",
    "y_predict = random_forest.predict(X_test)\n",
    "\n",
    "#cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict, labels = [1,0])\n",
    "print(cnf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "print(tn,fp,fn,tp)\n",
    "specificity = tn / (tn+fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall_or_sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(\"Specificity :\", round(specificity,2))\n",
    "print(\"Precision :\", round(precision, 2))\n",
    "print(\"Recall or Sensitivity :\", round(recall_or_sensitivity, 2))\n",
    "print(\"F Score\",f1_score(y_test, y_predict))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(random_forest.feature_importances_)):\n",
    "    feature = random_forest.feature_importances_[i]\n",
    "    print(feature,\":\",x_cols[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Random Forest Best Tree Measures\")\n",
    "# y_predict = best_tree.predict(X_test)\n",
    "\n",
    "# #cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "# cnf_matrix = confusion_matrix(y_test, y_predict, labels = [1,0])\n",
    "# print(cnf_matrix)\n",
    "\n",
    "# tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "# specificity = tn / (tn+fp)\n",
    "# precision = tp / (tp + fp)\n",
    "# recall_or_sensitivity = tp / (tp + fn)\n",
    "\n",
    "# print(\"Specificity :\", round(specificity,2))\n",
    "# print(\"Precision :\", round(precision, 2))\n",
    "# print(\"Recall or Sensitivity :\", round(recall_or_sensitivity, 2))\n",
    "# print(\"F Score\",f1_score(y_test, y_predict))\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(best_tree.feature_importances_)):\n",
    "#     feature = best_tree.feature_importances_[i]\n",
    "#     print(feature,\":\",x_cols[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Measures\n",
      "[[8 0]\n",
      " [1 3]]\n",
      "Specificity : 0.75\n",
      "Precision : 0.89\n",
      "Recall or Sensitivity : 1.0\n",
      "F Score 0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Measures\")\n",
    "y_predict = clf.predict(X_test)\n",
    "\n",
    "#cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "cnf_matrix = confusion_matrix(y_test, y_predict, labels = [1,0])\n",
    "print(cnf_matrix)\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "precision = tp / (tp + fp)\n",
    "recall_or_sensitivity = tp / (tp + fn)\n",
    "\n",
    "print(\"Specificity :\", round(specificity,2))\n",
    "print(\"Precision :\", round(precision, 2))\n",
    "print(\"Recall or Sensitivity :\", round(recall_or_sensitivity, 2))\n",
    "print(\"F Score\",f1_score(y_test, y_predict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
